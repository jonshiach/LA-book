(vector-spaces-chapter)=

:::{index} Vector spaces
:::

# Vector spaces

A vector space is a set of objects called vectors that satisfy axioms of vector addition and scalar multiplication. As the name suggests, vectors in [Euclidean space](euclidean-space-section) that we met in the chapter on vectors form a vector space but so do lots of other types of mathematical objects. The use of the term *vector* when dealing with vector spaces could be matrices, polynomial functions, numbers etc. 

Vector spaces are abstract and their purpose may not be apparent upon first meeting them. Geoffrey Scott gives a good explanation of <a href="https://www.math.toronto.edu/gscott/WhatVS.pdf" target="_blank">why we need vector spaces</a> which is paraphrased here. Consider the following three problems

- Problem 1: Find $x_1, x_2, x_3 \in \mathbb{R}$ that satisfy

$$ x_1 \begin{pmatrix} 2 \\ -1 \\ 1 \end{pmatrix} + x_2 \begin{pmatrix} 1 \\ 2 \\ 0 \end{pmatrix} + x_3 \begin{pmatrix} 3 \\ 1 \\ -1 \end{pmatrix} = \begin{pmatrix} 6 \\ 2 \\ 0 \end{pmatrix}. $$

- Problem 2: Find $x_1, x_2, x_3 \in \mathbb{R}$ such that

$$ x_1 (2t^2 - t + 1) + x_2 (t^2 + 2t -2) + x_3 (0t^2 + t) = 2t^2 + 5t + 1.$$

- Problem 3: Find $x_1, x_2, \ldots \in \mathbb{C}$ such that

$$ \sum_{n=1}^\infty x_n cos(n \pi t) = e^{5nt}. $$

Problems 1, 2 and 3 are described using three different mathematical objects. Problem 1 uses vectors, problem 2 uses polynomials and problem 3 uses trigonometric functions. On further inspection we can see that these three problems are all similar and involve solving a system of linear equations. We know how to solve problem 1 using the methods from the [chapter on systems of linear equations](systems-of-linear-equations-chapter) so can we use these to solve problems 2 and 3 and other problems using different mathematical objects?

To answer this we could state theorems for each type of mathematical object, e.g.,

> "Suppose you have a collection of columns vectors *or* polynomials *or* functions *or* any other type of mathematical object that can be multiplied by numbers and added together $\ldots$"

So every time we encounter a similar problem to the ones above we would need to state a theorem and prove it. Mathematicians like to be concise so the term *vector space* was invented to mean any type of mathematical object that can be multiplied by numbers and added together. So instead of the rambling phrase above we could use

> "Let $V$ be a vector space $\ldots$"

(vector-spaces-definitions-section)=

## Definitions

:::{prf:definition} Binary operation
:label: binary-operation-definition

A **binary operation** is a mapping of two elements of the same set $S$ whose output is also an element of $S$. 

$$ f: S \times S \to S$$

The symbol $\times$ is used to denote the <a href="https://en.wikipedia.org/wiki/Cartesian_product" target="_blank">Cartesian product</a> and $\to$ denotes a mapping from one set to another.
:::

We have already met examples of binary operations in addition, multiplication, subtraction and division of real numbers. For $a,b \in \mathbb{R}$ then

- $f(a,b) = a + b$ is a real number.
- $f(a,b) = a \cdot b$ ($a$ multiplied by $b$) is a real number [^1].
- $f(a,b) = a - b$ is a real number.
- $f(a,b) = a \div b$ is a real number.

[^1]: The symbol $\times$ is often used to denote multiplication which strictly speaking should be denoted using $\cdot$ (which is often omitted).

Another example is for the set of all $2 \times 2$ matrices $M_{2 \times 2}(\mathbb{R})$, $f(A, B) = AB$ is a binary operation since $AB$ is also a $2 \times 2$ matrix.

:::{prf:definition} Field
:label: field-definition

A **field** is a set $F$ together with two binary operations on elements of $F$ called *addition* and *multiplication*. For $a,b \in F$ addition is written as $a + b$ and multiplication is written as $a \cdot b$.
:::

The classic example of a field is a set of numbers which will suffice for what we will be doing here. However, a field can be any set of objects for which the above definition is satisfied and you may meet other examples of fields in your studies in the future.

:::{prf:definition} Vector space
:label: vector-space-definition

A **vector space** over a field $F$ is a non-empty set $V$ of objects called vectors on which the binary operations below are defined

- **addition** $(+)$: $V \times V \to V$. For example, given two elements $u, v \in V$ we can 'add' them together to obtain another element $u + v \in V$.
- **scalar multiplication** $(\cdot )$: $F \times V \to V$. For example given $\alpha \in F$ and $u \in V$ we can 'multiply' $u$ by $\alpha$ to obtain another element $\alpha \cdot u \in V$
:::

For example, a field could be the set of all real numbers $\mathbb{R}$ and a vector space be the set of all vectors in $\mathbb{R}^3$ since we can add two vectors and multiply a vector by a scalar. Not all subsets of a field can be classified as a vector space, to do so the set $V$ must satisfy the following axioms. 

:::{index} Vector spaces ; axioms
:::

:::{prf:axiom} Axioms of a vector space
:label: vector-space-axioms

Let $u, v, w \in V$ and $\alpha, \beta \in F$, $V$ is a vector space if all of the following axioms are satisfied

- **A1**: Associativity of vector addition: $u + (v + w) = (u + v) + w$;
- **A2**: Commutativity of vector addition: $u + v = v + u$;
- **A3**: Identity element of vector addition: there exists an element $0 \in V$ such that $u + 0 = u$ for all $v \in V$;
- **A4**: Additive inverse: For every $u \in V$ there exists an element $- v \in V$, called the **additive inverse**, such that $u + (- u) = 0$;
- **M1**: Associativity of scalar multiplication: $\alpha(\beta u) = (\alpha \beta) u$;
- **M2**: Identity element of scalar multiplication: there exists an element $1$ called the **multiplicative identity** such that $1 u = u$;
- **M3**: Distributivity of scalar multiplication with respect to vector addition: $\alpha(u + v) = \alpha u + \alpha v$;
- **M4**: Distributivity of scalar multiplication with respect to addition: $(\alpha + \beta)u = \alpha u + \beta u$.
:::

The first group of four axioms are concerned with addition and the second group of four axioms are concerned with scalar multiplication. When the scalars are real numbers, e.g., $F = \mathbb{R}$, we call $V$ a *'real vector space'* which is short for a *'vector space over the field of real numbers'*. When the scalars are complex numbers, e.g., $F=\mathbb{C}$, we talk of a *'complex vector space'*.

We now list some basic properties for multiplication by scalars in a vector space.

:::{prf:theorem} Properties of vector spaces
:label: properties-of-vector-spaces-theorem

Let $V$ be a vector space over $F$ and $u \in V,\alpha\in F$. Then the following hold:

- $\alpha \cdot 0 = 0$;
- $0 \cdot u = 0$;
- if $\alpha \cdot u = 0$ then either $\alpha = 0$ or $u = 0$;
- $-(\alpha \cdot u) = (-\alpha)\cdot u = \alpha\cdot(-u)$.
:::

The name *'vector space'* indicates a connection with the study of vectors. Indeed our Euclidean spaces $\mathbb{R}^n$, as introduced in [Vectors](vectors-chapter), are vector spaces over $F=\mathbb{R}$. Addition and scalar multiplication, in the sense of a vector space, for $\mathbb{R}^n$ are as given in {prf:ref}`vector addition<vector-addition-definition>` and {prf:ref}`scalar multiplication<scalar-multiplication-of-a-vector-definition>` respectively. Euclidean vector spaces are often the first examples of vector spaces that a student meets. However, maybe they do not quite demonstrate the power behind this construction. The real motivation of the study of the vector spaces comes from the fact that a lot of more abstract sets, such as differentiable functions or matrices, can be viewed as vector spaces. Everything that we learn about vector spaces can be then applied to any set which satisfies the definition of a vector space. This means that the set of $m\times n$ matrices with matrix addition and scalar multiplication or the set of all polynomials of degree at most $n$, in some sense, behave in a very similar fashion to Euclidean space.

::::{prf:example}
:label: real-numbers-vector-space-example

Show that the following are vector spaces:

(i) &emsp; The set of real numbers over itself;

:::{dropdown} Solution (click to show)

We need to check that all of the axioms of vector spaces are satisfied. Here $V = \mathbb{R}$, $F = \mathbb{R}$ and let $u, v, w \in V$ and $\alpha, \beta \in \mathbb{R}$

- A1: $u + (v + w) = (u + v) + w \quad \checkmark$
- A2: $u + v = v + u \quad \checkmark$
- A3: $u + 0 = u \quad \checkmark$ (i.e., 0 is the identity element of addition)
- A4: $u + (-u) = 0 \quad \checkmark$ (i.e., the negative of any number is the additive inverse)
- M1: $\alpha(\beta u) = (\alpha \beta) u \quad \checkmark$
- M2: $1 u = u \quad \checkmark$ (i.e., 1 is the multiplicative identity of all numbers)
- M3: $\alpha(u + v) = \alpha u + \alpha v \quad \checkmark$
- M4: $(\alpha + \beta) u = \alpha u + \beta u \quad \checkmark$
:::

(ii) &emsp; The set of all polynomials of degree at most $n$ with real coefficients $P_n(\mathbb{R})$

$$ \begin{align*}
    p = p(x) := a_0x^0 + a_1x^1 + a_2x^2 + \cdots + a_nx^n = \sum_{i=0}^n a_ix^i,
\end{align*} $$

where $a_i \in \mathbb{R}$ and $x$ is some variable. Show that $P(\mathbb{R}_n)$ is a vector space.

:::{dropdown} Solution (click to show)

Let $u(x), v(x), w(x) \in P_n(\mathbb{R})$ where $u_i, v_i, w_i \in \mathbb{R}$ are the coefficients for $u(x)$, $v(x)$ and $w(x)$ respectively and $k\in \mathbb{R}$ is some scalar then we define

- Vector addition:

$$ \begin{align*}
    u(x) + v(x) &= (u_0 + v_0)x^0 + (u_1 + v_1)x^1 + \cdots + (u_n + v_n)x^n \\
    &= \sum_{i=0}^n (u_i + v_i)x^i.
\end{align*} $$

- Scalar multiplication:

$$ \begin{align*}
    k \cdot u(x) &= ku_0x^0 + ku_1x^1 + \cdots + ku_nx^n \\
    &= \sum_{i=0}^n ku_ix^i.
\end{align*} $$

- Additive identity element is the zero polynomial

$$ \begin{align*}
    0 = 0x^0 + 0x^1 + \cdots + 0x^n.
\end{align*} $$

- The additive inverse to the polynomial $p$ is

$$ \begin{align*}
    -u(x) &= (-u_0)x^0 + (-u_1)x^2 + \cdots + (-u_n)x^n \\
    &= \sum_{i=0}^n (-u_i)x^i \\
    &= -\sum_{i=0}^n u_ix^i.
\end{align*} $$

Checking the that axioms of vector spaces are satisfied

- A1: Associativity of addition
  
$$ \begin{align*}
    u(x) + (v(x) + w(x)) &= \displaystyle \sum_{i=0}^n (u_i + (v_i + w_i))x^i \\
    &= \displaystyle \sum_{i=0}^n ((u_i + v_i) + w_i)x^i \\
    &= (u(x) + v(x)) + w(x) \quad \checkmark
\end{align*} $$

- A2: Commutativity of addition
  
$$ \begin{align*}
    u(x) + v(x) &= \displaystyle \sum_{i=0}^n (u_i + v_i)x^i \\
    &= \displaystyle \sum_{i=0}^n (v_i + u_i)x^i \\
    &= v(x) + u(x) \quad \checkmark
\end{align*} $$

- A3: Identity element for addition
  
$$ \begin{align*}
    u(x) + 0 &= \displaystyle \sum_{i=0}^n (u_i + 0)x^i \\
    &= \displaystyle \sum_{i=0}^n u_ix^i \\
    &= u(x) \quad \checkmark
\end{align*} $$

- A4: Inverse element for addition
  
$$ \begin{align*}
    u(x) + (-u(x)) &= \displaystyle \sum_{i=0}^n(u_i + (-u_i)) x^i \\
    &= 0 \quad \checkmark
\end{align*} $$

- M1: Associativity of scalar multiplication
  
$$ \begin{align*}
    \alpha(\beta u(x)) &= \alpha \displaystyle \sum_{i=0}^n \beta u_i x^i \\
    &= \alpha \beta \displaystyle \sum_{i=0}^n u_i x^i \\
    &= (\alpha \beta) u(x) \quad \checkmark
\end{align*} $$

- M2: Identity element for scalar multiplication
  
$$ \begin{align*}
    1 \cdot u(x) &= \displaystyle \sum_{i=0}^n 1 u_i x^i \\
    &= \displaystyle \sum_{i=0}^n u_i x^i \\
    &= u(x) \quad \checkmark
\end{align*} $$

- M3: Distributivity of scalar multiplication
  
$$ \begin{align*}
    \alpha (u(x) + v(x)) &= \alpha \sum (u_i + v_i) x^i \\
    &= \alpha \sum u_i x^i + \alpha v_i x^i \\
    &= \alpha u(x) + \alpha v(x) \quad \checkmark
\end{align*} $$

- M4: Distributivity of scalar multiplication over addition

$$ \begin{align*}
    (\alpha + \beta) u(x) &= (\alpha + \beta) \displaystyle \sum_{i=0}^n u_i x^i \\
    &= \alpha \displaystyle \sum_{i=0}^n u_i x^i + \beta \displaystyle \sum_{i=0}^n u_i x^i \\
    &= \alpha u(x) + \beta u(x) \quad \checkmark
\end{align*} $$
:::
::::

## Examples of non-vector spaces

Of course not all sets are vector spaces. For example, consider the set of integers $\mathbb{Z}$ over the field $F=\mathbb{R}$. It is easy to show that the {prf:ref}`axioms A1 to A4<vector-space-axioms>` are satisfied for the set of integers. The problem comes when one tries to define scalar multiplication. From the {prf:ref}`definition of scalar multiplication<vector-space-definition>`, $\mathbb{R} \times \mathbb{Z} \to \mathbb{Z}$ so for $u \in \mathbb{Z}$ and $\alpha \in \mathbb{R}$, $\alpha \cdot x\in \mathbb{Z}$. However, this is not always the case, for example, when $u=1$ and $\alpha = \frac{1}{2}$ we have $\frac{1}{2} \cdot 1 = \frac{1}{2} \notin \mathbb{Z}$. This was an example of a proof by counterexample where we just need to show 1 instance where the axioms are not satisfied to prove that we do not have a vector space.

::::{prf:example}
:label: non-vector-space-example

Show that the following a not vector spaces:

(i) &emsp; The set of all positive real numbers, $\mathbb{R}_+$ over itself;

:::{dropdown} Solution (click to show)
We do not have an identity element for addition since $0 \notin \mathbb{R}_+$ so axiom A3 is not satisfied. Also, by axiom A4, if $u, v \in \mathbb{R}_+$ are two positive real numbers then $x + y > 0$ so no additive inverse exists.
:::

(ii) &emsp; $V$ is defined to be a parabola $y=x^2$ in $\mathbb{R}^2$, i.e., all the points in $\mathbb{R}^2$ defined by $V = {(x, x^2)}$.

:::{dropdown} Solution (click to show)
If we take the example $\mathbf{u} \in V$ such that $\mathbf{u} = (1, 1)^\mathsf{T}$ then the additive inverse $-\mathbf{u}^\mathsf{T} = (-1, -1) \notin V$ so $V$ is not a vector space.
:::
::::
